{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from os.path import  join\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from pennylane import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "\n",
    "from qmlhep.data_handling.dataset import ParticlePhysics\n",
    "from qmlhep.utils.helper import GridSearch, NestablePool, get_random_numbers\n",
    "from qmlhep.qml import AdamModel, OptunaModel\n",
    "from qmlhep.config import analisys_results_path, figures_path, use_gpu\n",
    "from qmlhep.utils.helper import get_features\n",
    "\n",
    "# Import fig style\n",
    "from qmlhep.utils.plot_results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Notebook\n",
    "\n",
    "Author: Miguel Ca√ßador Peixoto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the baseline performance using a XGBoost for classification\n",
    "\n",
    "This will use the training dataset with all datapoints and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a XGBoost with a full range of features and datapoints\n",
    "train = ParticlePhysics(\"train\", standardization=\"ML\").all_data_Dataframe()\n",
    "train.drop(columns=['name'], inplace=True)\n",
    "features = train.columns[:-2]\n",
    "\n",
    "X_train, y_train, w_train = train[features], train['label'], train['weights']\n",
    "\n",
    "# Retormalize weights\n",
    "w_train[y_train == 1] = (w_train[y_train == 1] / w_train[y_train == 1].sum()) * w_train.shape[0] / 2\n",
    "w_train[y_train == 0] = (w_train[y_train == 0] / w_train[y_train == 0].sum()) * w_train.shape[0] / 2\n",
    "\n",
    "test = ParticlePhysics(\"test\", standardization=\"ML\").all_data_Dataframe()\n",
    "test.drop(columns=['name'], inplace=True)\n",
    "X_test, y_test, w_test = test[features], test['label'], test['weights']\n",
    "\n",
    "# Retormalize weights\n",
    "w_test[y_test == 1] = (w_test[y_test == 1] / w_test[y_test == 1].sum()) * w_test.shape[0] / 2\n",
    "w_test[y_test == 0] = (w_test[y_test == 0] / w_test[y_test == 0].sum()) * w_test.shape[0] / 2\n",
    "\n",
    "# GPU\n",
    "if use_gpu:\n",
    "    tree_method = 'gpu_hist'\n",
    "else:\n",
    "    tree_method = 'hist'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU is available but set to False in config.py. It's very likely that this will take a long time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=1e-5,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1,\n",
    "    tree_method=tree_method\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train, sample_weight=w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred, sample_weight=w_test)\n",
    "\n",
    "# Plot ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred, sample_weight=w_test)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(fpr, tpr)#, label='AUC = {:.3f}'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False positive rate', fontsize=MEDIUM_SIZE+5)\n",
    "plt.ylabel('True positive rate', fontsize=MEDIUM_SIZE+5)\n",
    "plt.title('ROC curve (AUC = {:.3f})'.format(auc), fontsize=BIGGER_SIZE)\n",
    "\n",
    "# Set the tick label font size\n",
    "plt.tick_params(axis='both', which='major', labelsize=TICK_SIZE)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(join(figures_path, 'baseline_xgb.pdf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Performance (Top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ParticlePhysics(\"validation\", PCA=True).all_data_Dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = df[\"weights\"]\n",
    "label = df[\"label\"]\n",
    "df.drop(columns=[\"weights\", \"label\", \"name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = {}\n",
    "\n",
    "weights[label == 1] = (weights[label == 1] / weights[label == 1].sum()) * weights.shape[0] / 2\n",
    "weights[label == 0] = (weights[label == 0] / weights[label == 0].sum()) * weights.shape[0] / 2\n",
    "\n",
    "# Calculate AUC for each feature\n",
    "for feature in df.columns:\n",
    "    auc = roc_auc_score(label, df[feature], sample_weight=weights)\n",
    "    book[feature] = auc\n",
    "\n",
    "# Show top 5 in table format\n",
    "pd.DataFrame.from_dict(book, orient=\"index\", columns=[\"AUC\"]).sort_values(by=\"AUC\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SBS (k <>= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print(sorted(get_features(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ParticlePhysics(\"train\", features=get_features(5)).all_data_Dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = df[\"weights\"]\n",
    "label = df[\"label\"]\n",
    "df.drop(columns=[\"weights\", \"label\", \"name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = {}\n",
    "\n",
    "weights[label == 1] = (weights[label == 1] / weights[label == 1].sum()) * weights.shape[0] / 2\n",
    "weights[label == 0] = (weights[label == 0] / weights[label == 0].sum()) * weights.shape[0] / 2\n",
    "\n",
    "for feature in df.columns:\n",
    "    auc = roc_auc_score(label, df[feature], sample_weight=weights)\n",
    "    book[feature] = auc\n",
    "\n",
    "# Show top 5 in table format\n",
    "pd.DataFrame.from_dict(book, orient=\"index\", columns=[\"AUC\"]).sort_values(by=\"AUC\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 features by AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ParticlePhysics(\"train\").all_data_Dataframe()\n",
    "\n",
    "weights = df[\"weights\"]\n",
    "label = df[\"label\"]\n",
    "df.drop(columns=[\"weights\", \"label\", \"name\"], inplace=True)\n",
    "\n",
    "\n",
    "book = {}\n",
    "\n",
    "weights[label == 1] = (weights[label == 1] / weights[label == 1].sum()) * weights.shape[0] / 2\n",
    "weights[label == 0] = (weights[label == 0] / weights[label == 0].sum()) * weights.shape[0] / 2\n",
    "\n",
    "for feature in df.columns:\n",
    "    auc = roc_auc_score(label, df[feature], sample_weight=weights)\n",
    "    book[feature] = auc\n",
    "\n",
    "\n",
    "# Show top 5 in table format\n",
    "pd.DataFrame.from_dict(book, orient=\"index\", columns=[\"AUC\"]).sort_values(by=\"AUC\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14 (main, Sep  7 2022, 23:43:29) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cbcd73b0cf6e8670d138ed76222ff52a06fb6d9bdaf472bc1d3d243963e313a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
